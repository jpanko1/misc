{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Useful Data Wrangling Techniques Using Python Pandas and data.world    \n",
    "### This notebook demonstrates a collection of data wrangling problems I frequently encounter, and my approaches to solving them.    \n",
    "What this tutorial **is not**: \n",
    "* a comprehensive tutorial on data wrangling\n",
    "* the only or even the best solutions    \n",
    "\n",
    "What this tutorial **is**:\n",
    "* fun and interesting (hopefully)\n",
    "* things I encounter often in my work\n",
    "* the best solutions I'm aware of (at this time)\n",
    "\n",
    "### Agenda:\n",
    "1. Standardize a large, messy datetime column\n",
    "2. Change time zones\n",
    "3. \"Standardizing\" text (string) columns \n",
    "4. Multiprocessing\n",
    "5. Reshaping dataframes with melt, pivot, & groupby   \n",
    "\n",
    "### Dependencies     \n",
    "* We'll be using the following Python packages: pandas, numpy, matplotlib, fuzzywuzzy, time, pytz, re, and multiprocessing.     \n",
    "* The data is called using the datadotword Python package.    \n",
    "  * Instructions for installing and configuring for the first time: https://github.com/datadotworld/data.world-py and https://data.world/nrippner/explore-the-data-world-python-sdk.            \n",
    "  * If you installed datadotworld in the past, please ensure that you're using the latest version. In a terminal/command line enter:    \n",
    "  `pip install --upgrade datadotworld`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd               # data wrangling library\n",
    "import datadotworld as ddw        # data.world SDK\n",
    "import numpy as np                # data manipulation, math, linear algebra library\n",
    "import matplotlib.pyplot as plt   # matlab style data visualization library\n",
    "from fuzzywuzzy import process    # fuzzy string matching\n",
    "import time                       # to measure processing time\n",
    "import pytz                       # time zones\n",
    "import re                         # Python regex\n",
    "import multiprocessing as mp      # multicore distributed processing\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noah Rippner -- data scientist at data.world -- May, 2017 \n",
      "\n",
      "CPython 3.6.1\n",
      "IPython 6.0.0\n",
      "\n",
      "pandas 0.20.1\n",
      "numpy 1.12.1\n",
      "datadotworld 1.2.0\n",
      "fuzzywuzzy 0.15.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "% watermark -a \"Noah Rippner -- data scientist at data.world -- May, 2017\" -v \\\n",
    "                             -p pandas,numpy,datadotworld,fuzzywuzzy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standardize a large, messy datetime column      \n",
    "Note, hat tip to data.world user @hipplec for suggesting this technique on a [thread in data.world](https://data.world/databrett/white-house-visitors-2015-6/discuss/data-preparation/7533)     \n",
    "For this example, we'll use some data I've hosted [here](https://data.world/nrippner/my-dataset) on data.world. The data table we're interested is a selection of three columns from the White House Visitor Logs dataset covering the years 2008 through 2016.     \n",
    "![wrang_tut_1.png](https://data.world/api/nrippner/dataset/images/file/raw/wrang_tut_1.png)\n",
    "\n",
    "We can see that the data file -- dates.csv -- has 3 columns and nearly 6 million rows.   \n",
    "First, let's import the data from data.world.   \n",
    "**(!)**Note: due to the large size (6 million rows), we're going to using the \"Copy URL, Python/Pandas, or R code\" approach to importing this data into Python (as opposed to writing a query) to avoid the compute time associated with querying over so many cells. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wrang_tut_2.png](https://data.world/api/nrippner/dataset/images/file/raw/wrang_tut_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste results:\n",
    "dates_dataframe = pd.read_csv('https://query.data.world/s/hmbt8lm4cw6yj9vshigs178m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5914767, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAMEFIRST</th>\n",
       "      <th>NAMELAST</th>\n",
       "      <th>APPT_START_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stella</td>\n",
       "      <td>Adamopoulos</td>\n",
       "      <td>5/1/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muriel</td>\n",
       "      <td>Brosman</td>\n",
       "      <td>5/1/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avery</td>\n",
       "      <td>Brumfield</td>\n",
       "      <td>5/1/15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAMEFIRST     NAMELAST APPT_START_DATE\n",
       "0    Stella  Adamopoulos          5/1/15\n",
       "1    Muriel      Brosman          5/1/15\n",
       "2     Avery    Brumfield          5/1/15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dates_dataframe.shape)\n",
    "dates_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective now is to convert the `APPT_START_DATE column` to a Series of Pandas datetime objects. The column's dtype is currently numpy `object_` and the individual values are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "5/1/15 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(dates_dataframe.APPT_START_DATE.dtype)\n",
    "print(dates_dataframe.APPT_START_DATE[0], type(dates_dataframe.APPT_START_DATE[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like it should be relatively simple -- we could just pass the `df.APPT_START_DATE` to the `pandas.to_datetime()` function. Let's try it on a slice made up of the first five percent of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.18 seconds to complete 1/20 of the rows\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = pd.to_datetime(dates_dataframe.APPT_START_DATE[:295738])\n",
    "end = time.time()\n",
    "print(\"%.2f seconds to complete 1/20 of the rows\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.4 minutes to complete all 5.9 million rows\n"
     ]
    }
   ],
   "source": [
    "print(\"%.1f minutes to complete all 5.9 million rows\" % (((end-start) * 20) / 60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing 1/20 of the data on my machine took 52 seconds. At that rate, all the rows will take more than 17 minutes. Let's see if we can speed it up.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5914767\n",
      "Number of unique dates: 158151\n",
      "36.1 seconds\n",
      "Couldn't be parsed: 165\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", dates_dataframe.shape[0])\n",
    "print(\"Number of unique dates:\", len(dates_dataframe.APPT_START_DATE.unique()))\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "def lookup(series):\n",
    "    dates = {date:pd.to_datetime(date, errors='coerce') for date in series.unique()} \n",
    "    return series.map(dates)\n",
    "\n",
    "dates_dataframe['NewDate'] = lookup(dates_dataframe.APPT_START_DATE)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"%.1f seconds\" % (end-start))\n",
    "print(\"Couldn't be parsed:\", sum(dates_dataframe.NewDate.isnull()) - sum(dates_dataframe.APPT_START_DATE.isnull()) )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this example :\n",
    "* we define a function called `lookup` which is intended to take as its argument a Pandas Series\n",
    "* using `dictionary comprehension`, we iterate over each item in the set of unique values in our original series and map each to a `Pandas datetime` object created using the `to_datetime` function\n",
    "* the `errors='coerce'` parameter tells the `to_datetime` function to return `np.nan` for values for which a datetime format cannot be inferred\n",
    "* using the `pandas.Series.map` method, we return a new Series based on the key:value mappings in our dictionary comprehension.\n",
    "* using this approach, we finished in 42 seconds -- a 96% reduction in processing time!     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAMEFIRST</th>\n",
       "      <th>NAMELAST</th>\n",
       "      <th>APPT_START_DATE</th>\n",
       "      <th>NewDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stella</td>\n",
       "      <td>Adamopoulos</td>\n",
       "      <td>5/1/15</td>\n",
       "      <td>2015-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muriel</td>\n",
       "      <td>Brosman</td>\n",
       "      <td>5/1/15</td>\n",
       "      <td>2015-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avery</td>\n",
       "      <td>Brumfield</td>\n",
       "      <td>5/1/15</td>\n",
       "      <td>2015-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAMEFIRST     NAMELAST APPT_START_DATE    NewDate\n",
       "0    Stella  Adamopoulos          5/1/15 2015-05-01\n",
       "1    Muriel      Brosman          5/1/15 2015-05-01\n",
       "2     Avery    Brumfield          5/1/15 2015-05-01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5914767 entries, 0 to 5914766\n",
      "Data columns (total 4 columns):\n",
      "NAMEFIRST          object\n",
      "NAMELAST           object\n",
      "APPT_START_DATE    object\n",
      "NewDate            datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 180.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dates_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before moving on**, let's think about what caused Pandas `to_datetime` to take so long (17 minutes). Pandas `to_datetime` is processor intensive because it attempts to infer timestamp format, but it can be drastically sped up by including an additional argument: \"_`format=`_\".     \n",
    "\n",
    "`new_series = pd.to_datetime(old_series, format=\"%Y/%m/%d\")`     \n",
    " \n",
    "By specifying the format via the `format=` parameter, the `to_datetime` algorithm skips the step of trying to infer the format, resulting in much shorter processing time. However, as we'll see, we could not use the format argument with this data.    \n",
    "\n",
    "Let's take a closer look at the datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    2058611\n",
       "12    1351583\n",
       "14    1339330\n",
       "15     754861\n",
       "11     258637\n",
       "16     112105\n",
       "8       13309\n",
       "7        9488\n",
       "10       8393\n",
       "9        4049\n",
       "6        1848\n",
       "19       1639\n",
       "20        581\n",
       "18        325\n",
       "1           3\n",
       "17          2\n",
       "3           2\n",
       "5           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helpful technique to look at composition of a column\n",
    "\n",
    "# use apply method to change each value to type string\n",
    "dates_dataframe['APPT_START_DATE'] = dates_dataframe.APPT_START_DATE.apply(lambda x: str(x))\n",
    "\n",
    "# dictionary comprehension to create list of the length of each datetime string\n",
    "lengths = [len(j) for _, j in enumerate(dates_dataframe.APPT_START_DATE.values)]\n",
    "\n",
    "# convert to pandas Series in order to use the value_counts method\n",
    "lengths = pd.Series(lengths).value_counts()\n",
    "\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample                  Length         Count     \n",
      "-----------------------------------------------------\n",
      "2/24/10 10:30           length: 13     count: 2058611\n",
      "3/5/10 10:15            length: 12     count: 1351583\n",
      "12/13/09 16:00          length: 14     count: 1339330\n",
      "8/22/2010 12:30         length: 15     count:  754861\n",
      "5/1/15 7:00             length: 11     count:  258637\n",
      "12/12/2011 18:30        length: 16     count:  112105\n",
      "10/22/10                length: 8      count:   13309\n",
      "9/23/10                 length: 7      count:    9488\n",
      "12/12/2011              length: 10     count:    8393\n",
      "1/27/2011               length: 9      count:    4049\n",
      "5/1/15                  length: 6      count:    1848\n",
      "5/19/2009 7:00:00AM     length: 19     count:    1639\n",
      "2/24/2009 11:30:00AM    length: 20     count:     581\n",
      "9/24/20096:00:00PM      length: 18     count:     325\n",
      "                        length: 1      count:       3\n",
      "3/6/20099:30:00AM       length: 17     count:       2\n",
      "nan                     length: 3      count:       2\n",
      "41948                   length: 5      count:       1\n"
     ]
    }
   ],
   "source": [
    "# function to return a sample datetime string for a given length\n",
    "def inspect_date(length):\n",
    "    return dates_dataframe[dates_dataframe.APPT_START_DATE.str.len() == length]\\\n",
    "                                                     .APPT_START_DATE.values[0]\n",
    "\n",
    "# string formatting to format print output\n",
    "print(\"{:<20} {:^12} {:^15}\".format(\"Sample\", \"Length\", \"Count\"))\n",
    "print(\"-\" * 53)\n",
    "\n",
    "for i, j in zip(lengths.index, lengths.values):\n",
    "    result = inspect_date(i)\n",
    "    print(\"{:<20} {:>10} {:<2} {:>10} {:>7}\".format(result, \"length:\", \n",
    "                                                    len(result), \"count:\", j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The take-away here** is that the datetime column lacks a consistent format. Some entries contain `hour:minute:seconds` and some don't. Sometimes the year is represented with 4 digits, sometimes only 2.    \n",
    "\n",
    "When we specify a format using `\"format=\"` in the function call, `to_datetime` throws an exception when encountering an unexpected type of datetime format. \n",
    "\n",
    "As far as I can tell our best bet (because of the lack of a consistent format) was the technique we used above, in which we used `to_datetime` on the set of unique values, and transformed the Series with the `map` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Changing time zones     \n",
    "This is pretty straightforward, but worth looking at.    \n",
    "\n",
    "First, let's download and import some timestamp data that has hour:minute:second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = ddw.query('nrippner/datetime-sample',\n",
    "                    'SELECT * FROM time_data LIMIT 1000').dataframe\n",
    "\n",
    "time_df['created_date'] = pd.to_datetime(time_df.created_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `created_date` column (after feeding it to the `to_datetime` function) is a datetime64 object.  \n",
    "* The individual objects that the `created_date` column comprises are pandas Timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "id              1000 non-null int64\n",
      "created_date    1000 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1)\n",
      "memory usage: 15.7 KB\n"
     ]
    }
   ],
   "source": [
    "time_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-04 00:23:34\n",
      "<class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "item = time_df.created_date[0]\n",
    "print(item)\n",
    "print(type(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine that we want to convert the data to Central time. By default, pandas Timestamp objects are _time zone agnostic_. Therefore, we have to ascertain the baseline timezone, because the data alone will not tell us. In this case, let's assume that I either contacted the database administrator or the database's documentation and learned that the time stamps were measured in UTC format (a common standard for databases).   \n",
    "     \n",
    "Knowing we're starting from UTC, here's how to go about changing the time zone in pandas. We'll use the `pytz` to get a list of time zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tz = pytz.all_timezones\n",
    "#all_tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['central_tz'] = time_df.created_date.apply(lambda x: x.tz_localize('UTC').tz_convert('US/Central'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time zone: US/Central\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>central_tz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>2016-06-04 00:23:34</td>\n",
       "      <td>2016-06-03 19:23:34-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556</td>\n",
       "      <td>2016-06-04 04:28:40</td>\n",
       "      <td>2016-06-03 23:28:40-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>565</td>\n",
       "      <td>2016-06-04 20:39:05</td>\n",
       "      <td>2016-06-04 15:39:05-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655</td>\n",
       "      <td>2016-06-05 22:43:03</td>\n",
       "      <td>2016-06-05 17:43:03-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1555</td>\n",
       "      <td>2016-06-17 01:07:05</td>\n",
       "      <td>2016-06-16 20:07:05-05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        created_date                central_tz\n",
       "0   555 2016-06-04 00:23:34 2016-06-03 19:23:34-05:00\n",
       "1   556 2016-06-04 04:28:40 2016-06-03 23:28:40-05:00\n",
       "2   565 2016-06-04 20:39:05 2016-06-04 15:39:05-05:00\n",
       "3   655 2016-06-05 22:43:03 2016-06-05 17:43:03-05:00\n",
       "4  1555 2016-06-17 01:07:05 2016-06-16 20:07:05-05:00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"time zone:\", time_df.central_tz[0].tz)\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. \"Standardizing\" text (string) columns      \n",
    "In this section, we'll see how to correct discrepancies between two columns.     \n",
    "\n",
    "> The typical use case is when you want to join two separate datasets, each with a common column to join on (for example, city name). More often than not we find spelling, syntax, or formatting differences between columns, which need to be brought into symmetry prior to executing a join.    \n",
    "\n",
    "In this example, our goal is to join two datasets on a \"Country\" column. In this case, we're going to join a dataset on refugees by country with one for population by country, with the goal of creating a \"Refugees Per Capita\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee_df = ddw.query('nrippner/refugee-host-nations',\n",
    "                       ''' SELECT `unhcr_2015.csv/unhcr_2015`.`Refugees (incl. refugee-like situations)` as Refugees,\n",
    "                                  `unhcr_2015.csv/unhcr_2015`.`Country / territory of asylum/residence` as Country\n",
    "                           FROM `unhcr_2015.csv/unhcr_2015` ''').dataframe\n",
    "\n",
    "refugee_df = refugee_df[refugee_df.Refugees != '*']\n",
    "refugee_df['Refugees'] = pd.to_numeric(refugee_df.Refugees)\n",
    "refugee_df = refugee_df.groupby('Country', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = ddw.query('nrippner/refugee-host-nations',\n",
    "                        '''SELECT `worldbank_indicators.csv/worldbank_indicators`.`2015 [YR2015]` as Population_2015,\n",
    "                           `worldbank_indicators.csv/worldbank_indicators`.`Country Name` as Country\n",
    "                            FROM `worldbank_indicators.csv/worldbank_indicators`\n",
    "                            WHERE `worldbank_indicators.csv/worldbank_indicators`.`Series Name`\n",
    "                            LIKE \"Population, total\"''').dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The refugee dataframe has 170 unique Countries\n",
      "The population dataframe has 244 unique Countries\n"
     ]
    }
   ],
   "source": [
    "print(\"The refugee dataframe has %d unique Countries\" % len(refugee_df.Country.unique()))\n",
    "print(\"The population dataframe has %d unique Countries\" % len(population_df.Country.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 out of 170 unique countries in refugee_df are in population_df\n",
      "143 out of 244 unique countries in population_df are in refugee_df\n"
     ]
    }
   ],
   "source": [
    "A = sum(pd.Series(refugee_df.Country.unique()).isin(population_df.Country))\n",
    "B = sum(pd.Series(population_df.Country.unique()).isin(refugee_df.Country))\n",
    "print(\"%d out of %d unique countries in refugee_df are in population_df\" % (A, len(refugee_df.Country.unique())))\n",
    "print(\"%d out of %d unique countries in population_df are in refugee_df\" % (B, len(population_df.Country.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the 27 countries in refugee_df that don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                                       Bahamas\n",
       "17              Bolivia (Plurinational State of)\n",
       "30                          Central African Rep.\n",
       "34                          China, Hong Kong SAR\n",
       "36                                         Congo\n",
       "41                                    Czech Rep.\n",
       "42                                 Côte d'Ivoire\n",
       "43                   Dem. People's Rep. of Korea\n",
       "44                        Dem. Rep. of the Congo\n",
       "47                                Dominican Rep.\n",
       "49                                         Egypt\n",
       "58                                        Gambia\n",
       "73                        Iran (Islamic Rep. of)\n",
       "84                                    Kyrgyzstan\n",
       "100             Micronesia (Federated States of)\n",
       "108                                        Nauru\n",
       "126                                Rep. of Korea\n",
       "127                              Rep. of Moldova\n",
       "133        Serbia and Kosovo (S/RES/1244 (1999))\n",
       "136                                     Slovakia\n",
       "147                             Syrian Arab Rep.\n",
       "150    The former Yugoslav Republic of Macedonia\n",
       "161                      United Rep. of Tanzania\n",
       "162                     United States of America\n",
       "165           Venezuela (Bolivarian Republic of)\n",
       "166                                     Viet Nam\n",
       "167                                        Yemen\n",
       "dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_unique = pd.Series(refugee_df.Country.unique())\n",
    "countries_unique[~countries_unique.isin(population_df.Country)]\n",
    "# (the ~ symbol before \"countries\" means \"not\")\n",
    "# the items from refugee_df.Country that are not in population_df.Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's correct the country names so the two dataframes match.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use list comprehension, the Python \"enumerate\" function, \n",
    "# and the pandas Series.isin() method to make list of non-matching countries\n",
    "no_match = [[i, refugee_df.Country.unique()[i]] for i, j in \n",
    "             enumerate(pd.Series(refugee_df.Country.unique()).isin(population_df.Country)) if not j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 'Bahamas'],\n",
       " [17, 'Bolivia (Plurinational State of)'],\n",
       " [30, 'Central African Rep.'],\n",
       " [34, 'China, Hong Kong SAR'],\n",
       " [36, 'Congo'],\n",
       " [41, 'Czech Rep.'],\n",
       " [42, \"Côte d'Ivoire\"],\n",
       " [43, \"Dem. People's Rep. of Korea\"],\n",
       " [44, 'Dem. Rep. of the Congo'],\n",
       " [47, 'Dominican Rep.'],\n",
       " [49, 'Egypt'],\n",
       " [58, 'Gambia'],\n",
       " [73, 'Iran (Islamic Rep. of)'],\n",
       " [84, 'Kyrgyzstan'],\n",
       " [100, 'Micronesia (Federated States of)'],\n",
       " [108, 'Nauru'],\n",
       " [126, 'Rep. of Korea'],\n",
       " [127, 'Rep. of Moldova'],\n",
       " [133, 'Serbia and Kosovo (S/RES/1244 (1999))'],\n",
       " [136, 'Slovakia'],\n",
       " [147, 'Syrian Arab Rep.'],\n",
       " [150, 'The former Yugoslav Republic of Macedonia'],\n",
       " [161, 'United Rep. of Tanzania'],\n",
       " [162, 'United States of America'],\n",
       " [165, 'Venezuela (Bolivarian Republic of)'],\n",
       " [166, 'Viet Nam'],\n",
       " [167, 'Yemen']]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of lists that pd.DataFrame will accept\n",
    "no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "no_match = pd.DataFrame(no_match, index=range(len(no_match)), columns=['idx', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzy matching, list comprehension, pd.Series.isin and enumerate to help find matches\n",
    "# add results as a new column in our dataframe for easy viewing\n",
    "no_match['Matches'] = [process.extractBests(j, population_df.Country.unique(), limit=3,\n",
    "                        score_cutoff=70) for _, j in enumerate(no_match.Country.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 'Bahamas'],\n",
       " [17, 'Bolivia (Plurinational State of)'],\n",
       " [30, 'Central African Rep.'],\n",
       " [34, 'China, Hong Kong SAR'],\n",
       " [36, 'Congo'],\n",
       " [41, 'Czech Rep.'],\n",
       " [42, \"Côte d'Ivoire\"],\n",
       " [43, \"Dem. People's Rep. of Korea\"],\n",
       " [44, 'Dem. Rep. of the Congo'],\n",
       " [47, 'Dominican Rep.'],\n",
       " [49, 'Egypt'],\n",
       " [58, 'Gambia'],\n",
       " [73, 'Iran (Islamic Rep. of)'],\n",
       " [84, 'Kyrgyzstan'],\n",
       " [100, 'Micronesia (Federated States of)'],\n",
       " [108, 'Nauru'],\n",
       " [126, 'Rep. of Korea'],\n",
       " [127, 'Rep. of Moldova'],\n",
       " [133, 'Serbia and Kosovo (S/RES/1244 (1999))'],\n",
       " [136, 'Slovakia'],\n",
       " [147, 'Syrian Arab Rep.'],\n",
       " [150, 'The former Yugoslav Republic of Macedonia'],\n",
       " [161, 'United Rep. of Tanzania'],\n",
       " [162, 'United States of America'],\n",
       " [165, 'Venezuela (Bolivarian Republic of)'],\n",
       " [166, 'Viet Nam'],\n",
       " [167, 'Yemen']]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 80\n",
    "no_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these worked well, but for some reason Venezuela (line 18) and Kyrgyzstan (line 7) didn't yield a match (although they probably should have).    \n",
    "We'll use pd.Series.str.contains to manually take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population_2015</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>31108083.0</td>\n",
       "      <td>Venezuela, RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Population_2015        Country\n",
       "207       31108083.0  Venezuela, RB"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df[population_df.Country.str.contains('Venez')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we'll create a nested dictionary to input into the pd.DataFrame.replace function on the refugee_df dataframe.    \n",
    "* The dictionary targets one column in the refugee_df dataframe: 'Country'.    \n",
    "* The pd.DataFrame.replace function will look within the refugee_df.Country column, find each key in the lower nested dictionary, and replace them with their corresponding values.   \n",
    "\n",
    "This process is (when possible), transforming the country names in refugee_df to match correctly with the same country's name in population_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repl = { 'Country' : {'Czech Rep.':'Czech Republic',\n",
    "                      'Dominican Rep.':'Dominican Republic',\n",
    "                      'Egypt':'Egypt, Arab Rep.',\n",
    "                      'Micronesia (Federated States of)':'Micronesia, Fed. Sts.',\n",
    "                      'Gambia':'Gambia, The',\n",
    "                      'China, Hong Kong SAR':'Hong Kong SAR, China',\n",
    "                      'Iran (Islamic Rep. of)':'Iran, Islamic Rep.',\n",
    "                      'Kyrgyzstan':'Kyrgyz Republic',\n",
    "                      'Rep. of Korea':'Korea, Rep.',\n",
    "                      'Serbia and Kosovo (S/RES/1244 (1999))':'Serbia',\n",
    "                      'Slovakia':'Slovak Republic',\n",
    "                      'Syrian Arab Rep.':'Syrian Arab Republic',\n",
    "                      'United Rep. of Tanzania':'Tanzania',\n",
    "                      'United States of America':'United States',\n",
    "                      'Venezuela (Bolivarian Republic of)':'Venezuela, RB',\n",
    "                      'Viet Nam':'Vietnam',\n",
    "                      'Yemen':'Yemen, Rep.',\n",
    "                      'Bahamas':'Bahamas, The',\n",
    "                      'Bolivia (Plurinational State of)':'Bolivia',\n",
    "                      'Central African Rep.':'Central African Republic',\n",
    "                      'Côte d\\'Ivoire':'Cote d\\'Ivoire',\n",
    "                      'Dem. Rep. of the Congo':'Congo, Dem. Rep.',\n",
    "                      'Congo':'Congo, Rep.',\n",
    "                      'Rep. of Moldova':'Moldova',\n",
    "                      'The former Yugoslav Republic of Macedonia':'Macedonia, FYR',\n",
    "                      'Dem. People\\'s Rep. of Korea':'Korea, Dem. People’s Rep.'\n",
    "                     }\n",
    "       }\n",
    "\n",
    "refugee_df.replace(repl, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of number of non-matching country names _________1\n",
      "which country were we unable to match? ________________Nauru\n"
     ]
    }
   ],
   "source": [
    "ref_unique = pd.Series(refugee_df.Country.unique())\n",
    "a = 'count of number of non-matching country names'\n",
    "print(\"{} {:_>10}\".format(a, len(ref_unique[~ref_unique.isin(population_df.Country)])))\n",
    "b = 'which country were we unable to match?'\n",
    "print(\"{} {:_>21}\".format(b, ref_unique[~ref_unique.isin(population_df.Country)].values[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a matching column in each dataframe to join on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Refugees</th>\n",
       "      <th>Population_2015</th>\n",
       "      <th>Refugees_Per_Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>257553</td>\n",
       "      <td>32526562.0</td>\n",
       "      <td>0.007918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>79</td>\n",
       "      <td>2889167.0</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>94161</td>\n",
       "      <td>39666519.0</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>15537</td>\n",
       "      <td>25021974.0</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>15</td>\n",
       "      <td>91818.0</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Country  Refugees  Population_2015  Refugees_Per_Cap\n",
       "0          Afghanistan    257553       32526562.0          0.007918\n",
       "1              Albania        79        2889167.0          0.000027\n",
       "2              Algeria     94161       39666519.0          0.002374\n",
       "3               Angola     15537       25021974.0          0.000621\n",
       "4  Antigua and Barbuda        15          91818.0          0.000163"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframes\n",
    "refugee_df = refugee_df.merge(population_df, on='Country', how='inner')\n",
    "\n",
    "# create new feature\n",
    "refugee_df['Refugees_Per_Cap'] = refugee_df.Refugees / refugee_df.Population_2015\n",
    "\n",
    "refugee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multiprocessing      \n",
    "Hat tip to [this blog](http://www.racketracer.com/2016/07/06/pandas-in-parallel/), where I discovered this technique.      \n",
    "Sometimes despite our best efforts to write good Python/Pandas code, we have complex computations that we'd like to speed up. For processor-intensive jobs, multiprocessing is a solution.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single job: 101.79\n",
      "multiprocessor: 29.33\n"
     ]
    }
   ],
   "source": [
    "#import multiprocessor as mp\n",
    "\n",
    "# first, define the function that you want to distribute across multiple CPU cores\n",
    "# Note, this is a poorly written function, so we can play with multiprocessing\n",
    "def func(s_split):\n",
    "    \n",
    "    def apply_func(x):\n",
    "        count = 0\n",
    "        for letter in list(x):\n",
    "            for country in population_df.Country.values:\n",
    "                if letter in list(country):\n",
    "                    count += 1\n",
    "        return count\n",
    "    \n",
    "    for n in range(20):\n",
    "        out = s_split.apply(apply_func)\n",
    "    return out\n",
    "\n",
    "# multiprocessing\n",
    "num_partitions = 10\n",
    "num_cores = 6\n",
    "\n",
    "def parallelize_series(s, func):\n",
    "    s_split = np.array_split(s, num_partitions)\n",
    "    pool = mp.Pool(num_cores)\n",
    "    output = pd.concat(pool.map(func, s_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return output\n",
    "\n",
    "start = time.time()\n",
    "func(refugee_df.Country)\n",
    "end = time.time()\n",
    "print(\"single job: %.2f\" % (end - start))\n",
    "\n",
    "start = time.time()\n",
    "ref_unique['letter_counts'] = parallelize_series(refugee_df.Country, func)\n",
    "end = time.time() \n",
    "print(\"multiprocessor: %.2f\" % (end - start))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the improvement in processing time.   \n",
    "The screenshot shows the jobs running concurrently on different cores of my quad-core laptop.\n",
    "\n",
    "![wrang_tut_3.png](https://data.world/api/nrippner/dataset/images/file/raw/wrang_tut_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reshaping dataframes with melt & pivot    \n",
    "\n",
    "**transform from \"wide\" to \"long\" format using melt**    \n",
    "For this exercise, we'll use the [Worldbank WDI Indicators data](https://data.world/worldbank/world-development-indicators) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population estimates by nation, by year\n",
    "pop_dataframe = ddw.query('worldbank/world-development-indicators',\n",
    "            'SELECT * FROM `WDI_csv.zip/WDI_csv/WDI_Data.csv/WDI_Data`'\\\n",
    "            'WHERE `WDI_csv.zip/WDI_csv/WDI_Data.csv/WDI_Data`.`Indicator Code`'\\\n",
    "                                                    '     = \"GC.TAX.TOTL.GD.ZS\"').dataframe\n",
    "# note, we're very near to releasing a product update that will greatly simplify the \n",
    "# syntax and structure of the way data is referenced in queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bermuda</td>\n",
       "      <td>BMU</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East Asia &amp; Pacific (IDA &amp; IBRD countries)</td>\n",
       "      <td>TEA</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5211232605849</td>\n",
       "      <td>11.0512571856422</td>\n",
       "      <td>10.8993770066324</td>\n",
       "      <td>10.8236623308498</td>\n",
       "      <td>11.0734365585208</td>\n",
       "      <td>None</td>\n",
       "      <td>10.7913613491258</td>\n",
       "      <td>10.3669821984149</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>BTN</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.51946726950630</td>\n",
       "      <td>8.41593233961713</td>\n",
       "      <td>9.23552702504043</td>\n",
       "      <td>13.1432965226147</td>\n",
       "      <td>13.5075777539729</td>\n",
       "      <td>14.7041481596257</td>\n",
       "      <td>14.3778834457536</td>\n",
       "      <td>13.3368926386372</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>BOL</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16.9648957779373</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>BIH</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>21.3974496867264</td>\n",
       "      <td>20.3141077335623</td>\n",
       "      <td>18.9605013977038</td>\n",
       "      <td>19.7000140636424</td>\n",
       "      <td>20.3224260222236</td>\n",
       "      <td>20.5007238483636</td>\n",
       "      <td>19.7778885682037</td>\n",
       "      <td>19.8172706811392</td>\n",
       "      <td>19.9688147877335</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Country Name Country Code  \\\n",
       "0                                     Bermuda          BMU   \n",
       "1  East Asia & Pacific (IDA & IBRD countries)          TEA   \n",
       "2                                      Bhutan          BTN   \n",
       "3                                     Bolivia          BOL   \n",
       "4                      Bosnia and Herzegovina          BIH   \n",
       "\n",
       "           Indicator Name     Indicator Code  1960  1961  1962  1963  1964  \\\n",
       "0  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None   \n",
       "1  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None   \n",
       "2  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None   \n",
       "3  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None   \n",
       "4  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None   \n",
       "\n",
       "   1965  ...               2007              2008              2009  \\\n",
       "0  None  ...               None              None              None   \n",
       "1  None  ...   10.5211232605849  11.0512571856422  10.8993770066324   \n",
       "2  None  ...   7.51946726950630  8.41593233961713  9.23552702504043   \n",
       "3  None  ...   16.9648957779373              None              None   \n",
       "4  None  ...   21.3974496867264  20.3141077335623  18.9605013977038   \n",
       "\n",
       "               2010              2011              2012              2013  \\\n",
       "0              None              None              None              None   \n",
       "1  10.8236623308498  11.0734365585208              None  10.7913613491258   \n",
       "2  13.1432965226147  13.5075777539729  14.7041481596257  14.3778834457536   \n",
       "3              None              None              None              None   \n",
       "4  19.7000140636424  20.3224260222236  20.5007238483636  19.7778885682037   \n",
       "\n",
       "               2014              2015  2016  \n",
       "0              None              None  None  \n",
       "1  10.3669821984149              None  None  \n",
       "2  13.3368926386372              None  None  \n",
       "3              None              None  None  \n",
       "4  19.8172706811392  19.9688147877335  None  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pop_dataframe.shape)\n",
    "pop_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_vars = ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code']\n",
    "pop_dataframe = pd.melt(pop_dataframe, \n",
    "                        id_vars=id_vars,\n",
    "                        value_vars=pop_dataframe.columns[4:].values, \n",
    "                        var_name='Year', \n",
    "                        value_name='Tax_Rev_Percent_GDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15048, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tax_Rev_Percent_GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bermuda</td>\n",
       "      <td>BMU</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>1960</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East Asia &amp; Pacific (IDA &amp; IBRD countries)</td>\n",
       "      <td>TEA</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>1960</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>BTN</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>1960</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>BOL</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>1960</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>BIH</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>1960</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Country Name Country Code  \\\n",
       "0                                     Bermuda          BMU   \n",
       "1  East Asia & Pacific (IDA & IBRD countries)          TEA   \n",
       "2                                      Bhutan          BTN   \n",
       "3                                     Bolivia          BOL   \n",
       "4                      Bosnia and Herzegovina          BIH   \n",
       "\n",
       "           Indicator Name     Indicator Code  Year Tax_Rev_Percent_GDP  \n",
       "0  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None  \n",
       "1  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None  \n",
       "2  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None  \n",
       "3  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None  \n",
       "4  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pop_dataframe.shape)\n",
    "pop_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transform from \"long\" to \"wide\" using pivot_table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numeric (errors='coerce' to convert strings to np.nan)\n",
    "pop_dataframe['Tax_Rev_Percent_GDP'] = pd.to_numeric(pop_dataframe.Tax_Rev_Percent_GDP, \n",
    "                                                                       errors='coerce')\n",
    "                     \n",
    "# pivot from long to wide\n",
    "index = ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code']\n",
    "pop_dataframe = pd.pivot_table(pop_dataframe, \n",
    "                               values='Tax_Rev_Percent_GDP', \n",
    "                               columns=['Year'],\n",
    "                               index=index,\n",
    "                               aggfunc=np.mean)\n",
    "# reset index\n",
    "pop_dataframe.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Year</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.883364</td>\n",
       "      <td>5.229756</td>\n",
       "      <td>6.039428</td>\n",
       "      <td>8.434998</td>\n",
       "      <td>9.123651</td>\n",
       "      <td>8.854568</td>\n",
       "      <td>7.471639</td>\n",
       "      <td>7.158330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.839672</td>\n",
       "      <td>18.313552</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.750393</td>\n",
       "      <td>37.431012</td>\n",
       "      <td>45.252935</td>\n",
       "      <td>35.142903</td>\n",
       "      <td>34.402769</td>\n",
       "      <td>37.185853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>ASM</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>ADO</td>\n",
       "      <td>Tax revenue (% of GDP)</td>\n",
       "      <td>GC.TAX.TOTL.GD.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Year    Country Name Country Code          Indicator Name     Indicator Code  \\\n",
       "0        Afghanistan          AFG  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   \n",
       "1            Albania          ALB  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   \n",
       "2            Algeria          DZA  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   \n",
       "3     American Samoa          ASM  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   \n",
       "4            Andorra          ADO  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   \n",
       "\n",
       "Year  1972  1973  1974  1975  1976  1977  ...        2006       2007  \\\n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN  ...    6.883364   5.229756   \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN  ...         NaN        NaN   \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN  ...   40.750393  37.431012   \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN  ...         NaN        NaN   \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN  ...         NaN        NaN   \n",
       "\n",
       "Year       2008       2009       2010       2011      2012       2013  \\\n",
       "0      6.039428   8.434998   9.123651   8.854568  7.471639   7.158330   \n",
       "1           NaN        NaN        NaN        NaN       NaN  16.839672   \n",
       "2     45.252935  35.142903  34.402769  37.185853       NaN        NaN   \n",
       "3           NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "4           NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "\n",
       "Year       2014  2015  \n",
       "0           NaN   NaN  \n",
       "1     18.313552   NaN  \n",
       "2           NaN   NaN  \n",
       "3           NaN   NaN  \n",
       "4           NaN   NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pop_dataframe.shape)\n",
    "pop_dataframe.head()\n",
    "# note that columns where all items were NaN were automatically dropped, \n",
    "# reducing the number of columns to 48."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for reading this notebook. I hope you enjoyed it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "710px",
    "left": "527.96px",
    "right": "20px",
    "top": "104.983px",
    "width": "650px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
